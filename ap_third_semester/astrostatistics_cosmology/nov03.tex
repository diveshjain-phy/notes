\documentclass[main.tex]{subfiles}
\begin{document}

\marginpar{Tuesday\\ 2020-11-3, \\ compiled \\ \today}

A \textbf{stationary distribution} for a Markov Chain is a probability distribution \(p(\vec{x})\) for \(\vec{x}\) in \(\Omega \) such that the following property holds: 
%
\begin{align}
p(\vec{y}) = \sum _{\vec{x} \in \Omega} \mathbb{P}(\vec{y} | \vec{x}) p(\vec{x})
\,,
\end{align}
%
where \(\mathbb{P}(\vec{y} | \vec{x})\) is the transition probability from \(\vec{x}\) to \(\vec{y}\): the probability that we are in \(\vec{y}\), given that we were in \(\vec{x}\) at the previous step. 
What this means is that after a step in the chain leaves \(p(\vec{x})\) unchanged. 

In terms of the transition matrix, the problem reads \(p_i = T_{ij} p_j\), so \(p_i\) is an eigenvector of \(T_{ij}\) with eigenvalue \(1\). 

In our case, we want to build a MC which converges to a stationary probability distribution which is our posterior. 
So, first we need to ask whether this can be done, and then how long it takes for us to converge to that distribution. 

\begin{theorem}
    A finite, ergodic Markov chain has a unique stationary distribution. 
\end{theorem}

A state has \textbf{period} \(k\) if any return to it requires a multiple of \(k\) steps. Formally, 
%
\begin{align}
k(\vec{x}) =  \gcd \qty{ n \in \mathbb{N}: \text{the probability of returning from \(\vec{x}\) to \(\vec{x}\) in \(n\) steps is } >0}
\,.
\end{align}
%

If \(k=1\) the state is aperiodic. 
If a MC is ergodic and one state is aperiodic then all states are.  

A state is \textbf{recurrent} if with probability 1 we will return to it at some point if we leave it.
It is called \textbf{transient} otherwise.

A recurrent state is \textbf{positive recurrent} if the expected return time is finite; \textbf{null recurrent} if it diverges. 

\begin{theorem}
    A finite, ergodic, positive recurrent, aperiodic Markov Chain converges to its stationary distribution as \(n \to \infty \). 
\end{theorem}

So, eventually convergence is ensured, but we must also design a MC which converges \emph{quickly}. 

Let us now give a practical example, with \(\Omega = \qty{A, B, C}\).
The transition matrix is 
%
\begin{align}
T_{ij} = 
\left[\begin{array}{ccc}
\num{.25} & \num{.5} & \num{0.25} \\ 
0 & \num{.5} & \num{.5} \\ 
\num{.33} & \num{.33} & \num{.34}
\end{array}\right]
\,,
\end{align}
%
as required all the rows are normalized to one. 
The initial condition is given by \(q_0 = [0, \num{.5}, \num{.5}]\).

The following steps can be calculated as \(q_n = q_0 (T^{n}) \).

Let us define \(m(s_i, s_j)\) as the mean time to go from \(s_i\) to \(s_j\). How do we compute it? We need to make sure that it is finite.
Let us fix a state, say \(C\). What is \(m(C, C)\)?

Suppose that the first step is from \(C\) to \(B\). Then, we will have \(m(C,C) = 1 + m(B, C)\). Similarly, if we go from \(C\) to \(A\) we have \(m(C, C) = 1 + m(A, C)\); while if we jump directly to \(C\) we have \(m(C, C) =1\). 

The overall recurrence time is obtained by integrating over all the possibilities: 
%
\begin{align}
m(C, C) &= 
\mathbb{P}(C | A) \qty[1 + m(A, C)] + 
\mathbb{P}(C | B) \qty[1 + m(B, C)] 
+  \mathbb{P}(C | C)  \\
&= 
\underbrace{\mathbb{P}(C |A ) +
\mathbb{P}(C |B) +
\mathbb{P}(C |C )}_{1} +
\mathbb{P}(C |A ) m(A, C) +
\mathbb{P}(C |B ) m(B, C) +
\,.
\end{align}

We can do a similar thing for the other recurrence times, this yields a linear system we can solve, in terms of the three unknowns \(m(*, C)\). 
In this case we get \(m(C, C) = \num{2.54}\), \(m(B, C) = \num{2.0}\), \(m(A,C) = \num{2.67}\). 

Therefore, this MC will admit a stationary distribution and converge to it.\footnote{Check out the convergence by downloading the notebook at \url{https://github.com/jacopok/notes/blob/master/ap_third_semester/astrostatistics_cosmology/figures/markov.ipynb}!}
We can calculate it through the left eigenvalue problem \(\pi = \pi T\). 

A Markov Chain is \textbf{reversible} if there exists a probability distribution \(\pi \) such that \(\mathbb{P}(x | y) \pi (y) = \mathbb{P}(y | x) \pi (x)\). 
This is called the \textbf{detailed balance} equation, and if it holds it tells us that \(\pi \) is the stationary distribution of the Markov chain: if we sum over \(y\) we get 
%
\begin{align}
\sum _{y} \mathbb{P}(x | y) \pi (y) = \sum _{y} \mathbb{P}(y | x) \pi (x) 
= \pi (x) \sum _{y} \mathbb{P}(y | x ) = \pi (x)
\,,
\end{align}
%
which is precisely the stationarity condition.

\subsection{Metropolis-Hastings} 

Suppose we have a posterior \(p(\vec{\theta})\), in terms of a parameter vector \(\vec{\theta}\). 

The current state is denoted as
%
\begin{align}
X_\theta = \qty(\theta_{1, t },  \dots, \theta_{n, t})
\,.
\end{align}

We choose a transition distribution \(Q\);
this can be some easy-to-sample distribution of our choosing. 

Then, the new state is \textbf{proposed} by updating the old position
%
\begin{align}
Y \sim Q ( \cdot | X_t)
\,,
\end{align}
%
and choose to accept it or reject it depending on the following: we draw a uniform variable, and accept with probability 
%
\begin{align}
\alpha (X_{t+1} = y | X_t = x) = 
\min \qty{ \frac{\mathscr{L}(\vec{y})}{\mathscr{L}(\vec{x})} \frac{Q(\vec{x} | \vec{y})}{Q(\vec{y} | \vec{x})}, 1}
\,.
\end{align}

Simply put, we favor steps which move us in a region of higher likelihood. 
The ratio of the \(Q\)s might well go away if we choose a symmetric transition matrix. 

This satisfies the detailed balance equation: let us show it. 
One side of the equation reads
%
\begin{align}
\underbrace{\alpha (\vec{y} | \vec{x}) Q (\vec{y} | \vec{x})}_{\text{transition probability}} p(\vec{x})
&= \min \qty{\frac{\mathscr{L}(\vec{y})}{\mathscr{L}(\vec{x})} 
\frac{Q(\vec{x} | \vec{y})}{Q(\vec{y} | \vec{x})}, 1} Q(\vec{y} | \vec{x}) p(\vec{x})  \\
&= \min \qty{Q(\vec{x} | \vec{y}) \mathscr{L}(\vec{y}), Q(\vec{y} | \vec{x}) \mathscr{L}(\vec{x})} \mathscr{L} (\vec{x} ) 
\,,
\end{align}
%
\todo[inline]{check calculation}

We apply Bayes' theorem\dots
Finally, we show that 
%
\begin{align}
\alpha (\vec{y} | \vec{x}) Q (\vec{y} | \vec{x}) p(\vec{x}) 
= \alpha (\vec{x} | \vec{y}) Q(\vec{x} | \vec{y}) p(\vec{y})
\,.
\end{align}



\end{document}
