\documentclass[main.tex]{subfiles}
\begin{document}

% \marginpar{Thursday \\ 2019-11-14, \\ compiled \\ \today}
% \section*{Thu Nov 14 2019}

% During inflation, the comoving Hubble radius (\(r_H = 1/\dot{a}\)) decreases.
Let us consider a region of radius approximately \(1 / H(t_b)\), where \(t_b\) is a certain moment before the start of the inflationary phase.
This region is expanded by many \(e\)-foldings through inflation, such that any inhomogeneities are smoothed out: this is the \textbf{cosmic no-hair theorem} \cite[pag.\ 159]{colespCosmology2002}.

% \(t_i\) is the beginning time of inflation, \(t_f\) is its end, \(t_\Lambda \) is the time when the cosmological constant became dominant, and then we get to now: \(t_0 \).

% What happened before inflation?

% The cosmic no-hair conjecture is what allows inflation to delete inhomogeneties.
So, there might have been perturbations before inflation: we cannot know.
Perturbations on scales larger than the cosmological horizon are not perceivable as perturbations: we only perceive our local mean value.

% Below the largest inflation scale, the perturbations are erased by inflation: we see perturbations on these scales which are produced during inflation.

\paragraph{Reheating}

The energy density of radiation through the inflationary period scales as \(\rho _r \propto a^{-4} \propto e^{-4 Ht}\), while the one of matter instead it scales as \(\rho _m \propto a^{-3} \propto e^{-3Ht}\) since \(a \propto e^{Ht}\).
Qualitatively speaking, as the universe rapidly expands it becomes basically \emph{devoid of particles}, and its temperature drops substantially.

At the end of inflation, \emph{reheating} takes place, substantially raising the temperature and allowing for the formation of most of the SM particles we observe today.
This is due to the latent energy released by our scalar field due to its coupling to the rest of the universe, which acts as a sort of viscous force.
Intuitively speaking, the field ``falls'' into its ground state and then oscillates ever slower, dissipating its energy in the process \cite[fig.\ 7.6]{colespCosmology2002}. 

% So we get that this latent energy \(\Delta V\) is of the order of \(T^{4}_{\text{rad}}\).
% \todo[inline]{This seems like a rather technical point to end on\dots Is there some larger meaning to be drawn from these last paragraphs?}

\section{Baryogenesis}

This is the process which led to the formation of baryons. 

% What is the typical temperature needed to produce baryon symmetry? 
% \todo[inline]{What is baryon symmetry?}
The main issue we seek to address is that of \textbf{baryon asymmetry}. In the Standard Model each fermion has a corresponding antifermion, and the same holds for the composite particles of quarks, such as mesons and baryons. 

We usually talk of baryons only; they are characterized by the conserved baryon number \(B\), which is the number of baryons minus the number of antibaryons.\footnote{This number can actually be computed from the number of quarks already, so it makes sense to discuss it even before the formation of proper baryons.}

Matter and antimatter annihilate if they meet, producing radiation (\(\gamma \) photons and/or other high-energy particles). 
This allows us to investigate the presence of antimatter in the universe: if there were patches of antimatter as well as patches of matter their boundaries would be regions of great \(\gamma \)-ray emission, which we would be able to detect as a background.
Observations then allow us to rule out the presence of antimatter regions large enough to have \(B = 0\) in the observable universe --- small patches of antimatter may exist, but there are not enough of them to balance out all the matter \cite[]{cohenMatterAntimatterUniverse1998}. 

This constitutes the problem of baryon asymmetry: it seems unnatural for the universe to start off with more baryons than antibaryons, all the known Standard Model interactions conserve \(B\), yet we observe more baryons than antibaryons.
% These questions are hard to answer without a grand unification theory, which.

% How much antimatter is there in the universe?
% A long time ago, it was thought that there might have been regions in the universe which were filled with antimatter by looking for a \(\gamma \)-ray background, but this was not found.
% We did not find them.

In particle physics the absolute number \(B\) is used, but in cosmology absolute numbers are not used: we work in terms of densities.
All number densities scale like \(a^{-3}\), so we need to normalize the difference \(n_b - n_a\) with another number density: we define: \(\eta/2 = (n_b - n_a) / (n_b + n_a)\). Here \(b\) means baryons, while \(a\) means antibaryons. 
% This is actually computed with quark numbers, so it can be computed even when protons and neutrons have not yet formed.

The reason for the factor 2 is given by how we can actually estimate this parameter: in the early universe, when the baryons were still relativistic, processes like \(b + \overline{b} \leftrightarrow 2 \gamma \) occurred at thermal equilibrium, so roughly speaking we should have had \(n_b \approx n_a \approx 2 n_\gamma \).

\todo[inline]{What would be the proper chemical-equilibrium considerations?}

Now, all of these densities scaled like \(a^{-3}\) from the moment the baryons became nonrelativistic to now. So, we have 
%
\begin{align}
2 \frac{n_b - n_a}{\underbrace{n_b + n_a}_{2 n_\gamma }} \approx \frac{n_{0b} - \overbrace{n_{0a}}^{\approx 0}}{n_{0\gamma}} \approx \frac{n_{0b}}{n_{0 \gamma }}  = \eta_0 
\,.
\end{align}
 
This allows us to estimate the asymmetry constant \(\eta \) with parameters measured today: the baryon number density and the photon number density. 

% It seems like the only antimatter known is the one which was formed by us, or cosmic rays.

For the baryon number density we can estimate \cprotect\footnote{The result comes about from the following code: \begin{lstlisting}[language=Python]
from astropy.cosmology import Planck15 as cosmo
import numpy as np
import astropy.units as u
from astropy.constants import codata2018 as ac
H0 = u.littleh *100 * u.km/u.s / u.Mpc
rhoC = 3 * H0**2 / (8 * np.pi * ac.G)
(rhoC * cosmo.Ob0 / ac.m_p).to(u.cm**-3 * u.littleh**2)
\end{lstlisting}}
%
\begin{align}
n_{0b} \approx \frac{\rho_{0b}}{m_p} = \frac{\Omega_{0b} \rho_C}{m_p} \approx \SI{5.46e-7}{cm^{-3} \littleh^2} \marginnote{\(\Omega_{0b}\approx 0.0486\).}
\,,
\end{align}
%
while for the photons we can find the number density by integrating the CMB Planckian: the result is \cprotect\footnote{The result comes about from the following code: \begin{lstlisting}[language=Python]
from astropy.cosmology import Planck15 as cosmo
import numpy as np
import astropy.units as u
from astropy.constants import codata2018 as ac
z3 = np.sum([n**-3 for n in range(1, 1000000)])
(2 * z3 / np.pi**2 * cosmo.Tcmb0**3 * (ac.k_B / ac.hbar / ac.c)**3).cgs
\end{lstlisting}}
%
\begin{align}
n_{0 \gamma } \approx \frac{2 \zeta (3)}{\pi^2} T_{0 \gamma }^3 \qty(\frac{k_B }{\hbar c})^3 \approx \SI{410}{cm^{-3}}
\,.
\end{align}

Combining these results yields 
%
\begin{align} \label{eq:baryon-to-photon-ratio}
\eta_0 \approx \num{3e-8} \Omega_{0b} h^2 \approx \num{1.3e-9} h^2 \approx \num{6.1e-10}
\,.
\end{align}

How do we interpret this result? It means that in the radiation-dominated epoch the asymmetry between baryons and antibaryons was very slight, about one part in a billion; most of the pairs annihilated but a bit of matter was leftover, and that is the matter we currently have. 

% The value \(\Omega_{0b} \approx 0.04\) is defined as 
% %
% \begin{align}
%   \rho_{0b} = \Omega_{0b} \rho _{c} 
% \,,
% \end{align}
% %
% where \(\rho_c = 3 H_0^2 / (8 \pi G)\).

% When we define the number of protons in the universe we also fix the number of neutrons, since the universe is globally neutral.
% So we can estimate: 
% %
% \begin{align}
%   n_{0b} = \frac{\rho_{0b}}{m_p} \approx \SI{1.12e-5}{cm^{-3}} \times h^2 \Omega_{0b}
% \,,
% \end{align}
% %
% where \(h \sim 0.7\),
% and similarly we can compute 
% %
% \begin{align}
%   n_{0 \gamma } \approx \SI{420}{cm^{-3}}
% \,,
% \end{align}
% %
% so we can 
% look at the baryon to photon number ratio: 
% %
% \begin{align}
%   \eta_0  = \frac{n_{0b}}{n_{0\gamma}}
%   \approx \num{3e-8} \Omega_{0b} h^2
% \,,
% \end{align}
% %
% why does this number have this value? 

% The denominator in \((n_b - n_a) / (n_b + n_a)\) is approximately \(2 n_{\gamma }\) then, and both the difference in the numerator and the numerator scale like \(a^{-3}\), so this value is a constant.
% We do not see antimatter, therefore \(n_a = 0\). So, we get 
%
% \begin{align}
%     \frac{n_b - n_a}{n_b + n_a} \approx \frac{n_b}{2 n_\gamma } = \frac{1}{2} \eta_0 
% \,.
% \end{align}
%
% This must then have been the case also in the matter dominated epoch, during which there was a very slight imbalance in baryons vs antibaryons.

In 1966, the Soviet physicist Sakharov postulated that in order to generate baryon-antibaryon asymmetry in the early universe there are three necessary conditions:  
\begin{enumerate}
    \item violation of baryon number conservation;
    \item \(C\) and \(CP\) violation (while \(CPT\) symmetry must hold for any well-behaved QFT);
    \item out-of-equilibrium processes.
\end{enumerate}

% These were proposed by a famous Soviet scientist.
\(B\) violation is needed for the existence of processes which can generate more baryons than antibaryons.
\(C\) violation is needed because otherwise any process which generates baryons would have a counterpart generating antibaryons occurring with the same probability. 
\(CP\) violation is needed because otherwise processes generating left-handed baryons would be balanced by processes generating right-handed antibaryons, and vice versa. 
Out-of-equilibrium processes are needed because otherwise \(B\)-increasing and \(B\)-reducing processes would balance out. 

\section{Decoupling of particle species}

Earlier we made the claim that neutrinos decouple at \(T \approx \SI{1}{MeV}\): let us justify this, and explore the concept of a particle species being \textbf{decoupled} in general.

We define the \emph{interaction rate} \(\Gamma \): it is the number of interactions per unit time that each particle undergoes.

The Hubble rate \(H = \dot{a} / a \) is also, dimensionally, an inverse time, so we can compare \(H\) and \(\Gamma \) directly. 
What does this comparison tell us?
We have seen earlier that the age of the universe is roughly given by \(1 / H \), while \(1/ \Gamma \) is the average time for an interaction to occur (modelling the interaction times as a Poisson process). 
So, if \(1 / H < 1 / \Gamma \), then on average the particle species has undergone on average \emph{less than one} interaction in the whole existence of the universe. This condition is called decoupling, and is equivalent to \(\Gamma < H\). 
If \(\Gamma  \ll H\) then the interaction basically does not happen. 

% baryons and antibaryons are practically speaking \emph{decoupled} if \(\Gamma \leq H\): this is equivalent to saying that the time of interaction is larger than the age of the universe.

% When are particles actually coupled or decoupled?
In general, \(\Gamma \) can be calculated as \(\Gamma = n \expval{\sigma v}\), where \(n\) is the number density, \(v\) is the velocity of the particles,  \(\sigma \) is the cross section of the interaction, and we average over the velocity distribution of the particles. 

% We need to distinguish the types of interactions we are dealing with.
In the Standard Model, interactions are mediated by gauge bosons, which can be either massless (like the photon) or massive (like the weak interaction \(W^{\pm}\) and \(Z\) bosons\footnote{Properly speaking, these bosons are not massive in general since they acquire their mass through the spontaneous breaking of the \(SU(2)_L \times U(1)_Y\) symmetry of the Standard Model to \(U(1)_{\text{em}}\), which happens below the scale of electroweak symmetry breaking \(\sim \SI{e2}{GeV}\). The bosons being massive yields an exponential cutoff \(e^{-mr}\) in the expression of the potential for the interaction (this is the \emph{Yukawa potential}), so at energies higher than the electroweak SB scale the weak interaction becomes long-range.}).

% At larger energies than those, the weak interaction also becomes long-range.

For massless boson mediators, the cross-section is (roughly) given by \(\sigma \sim \alpha^2 / T^2\), where \(g = \sqrt{4 \pi \alpha }\).

For massive boson mediators with mass \(m_x\), we need to distinguish between two cases: for temperatures \(T \leq m_{x}\), the cross section is of the order \(\sigma \sim G_x^2 T^2\), while for higher temperatures \(T > m_x\) we have \(\sigma \sim \alpha^2 / T^2\) as in the massless case.\footnote{The reason for this is that when we compute the cross section for an interaction with a massive boson we find an expression like 
%
\begin{align}
\sigma \sim \frac{s}{(s - m_x^2)^2}
\,,
\end{align}
%
where \(s\) is the square of the center-of mass energy of the interaction; if there is thermal equilibrium then typically we will have \(s \sim T^2\). We can then see that at high energies the expression is asymptotically \(\sigma \sim T^{-2}\), while at low energies it is \(\sigma \sim T^2 / m_x^{4}\). This expression also holds for \(m_x = 0\). 
}
% there is an inversion in the \(T\) dependence between long and short range interactions.
Typically, \(G_x = \alpha / m_x^2\). 

% This difference is because in general the formula is like 
% %
% \begin{align}
%   \sigma \sim \frac{T^{2}}{E^{4}}
% \,,
% \end{align}
% %
% and we either have \(E \sim m\) in the low-speed case, or \(E \sim T\) in the high-speed case.

% So, we know that \(\Gamma = n \expval{\sigma v}\).
Let us then estimate the decoupling temperatures in the two cases. 
In our computation, \(v\) is the relative velocity between the two particles; in both cases we assume that the particles are relativistic, therefore \(v \approx 1\). 
We will make very rough estimates, neglecting multiples like \(\pi \) in front of our expressions; the things we want to get right are the dimensionality and the asymptotic scaling of the equations.

\paragraph{Massless boson decoupling}

We know that the number density of particles scales like \(n \sim T^3 \sim a^{-3}\) in this radiation-dominated epoch, therefore the interaction rate will scale like 
%
\begin{align}
\Gamma \sim T^3 \sigma \sim T^{3} \frac{\alpha^2}{T^2} \sim \alpha^2 T
\,.
\end{align}

%  since \(T \sim 1/ a\).
What is the scaling of \(H\)? We can recover it from the first Friedmann equation (see equation \eqref{eq:time-temperature-relation}):
%
\begin{align}
  H = \sqrt{\frac{8 \pi G }{3}} g_{*}^{1/2} \qty(\frac{\pi^2}{30})^{1/2} T^2 \sim \frac{T^2}{m _{\text{pl}}}
\,,
\end{align}
%
since \(G \sim 1/m _{\text{pl}}^2\). The numeric factor we are neglecting is about a factor 10, only one order of magnitude, which is fine given the roughness of our calculation. 

Let us then see when \(\Gamma / H < 1\), which corresponds to decoupling:
%
\begin{align}
  \frac{\Gamma}{H} \sim \frac{\alpha^2 T m _{\text{pl}}}{T^2} \sim \alpha^2 m _{\text{pl}} \frac{1}{T}
\,,
\end{align}
%
so we have decoupling when \(T > \alpha^2 m _{\text{pl}}\).

For electromagnetism \(\alpha \approx 1 / 137\), so at temperatures larger than \(T \approx \SI{e16}{GeV}\) this massless photon is decoupled.

Note that decoupling occurs for \emph{very high} temperatures, meaning very early times, close to the Planck epoch; further, the photons start off decoupled and then couple. 
After this, there is no lower bound: they may remain coupled for arbitrarily low temperatures. 

\todo[inline]{Some comments are made about gravitational interactions, but what would \(\alpha_{\text{grav}}\) be? }

\todo[inline]{The calculation seems to yield \(T \approx \SI{e15}{GeV}\), or even less if we account for \(g_*\)\dots I guess it does not really matter but it seemed curious.}

% ``Above the Planck epoch, even gravitational interactions are decoupled''.

\paragraph{Massive boson decoupling}

It is of interest for us to consider the \emph{low-energy} situation, in which \(T < m_x\).
The opposite limit, \(T \gg m_x\), behaves like the massless case: we find an upper limit above which there is decoupling. 

So, we have \(\Gamma \sim T^3 G_x^2 T^2 = G_x^2 T^{5}\), to compare with \(H \sim T^2/ m _{\text{pl}}\): as before we take the ratio, to find 
%
\begin{align}
  \frac{\Gamma}{H} \sim \frac{T^5 G_x^2}{T^2 / m _{\text{pl}}} \sim G_x^2 m _{\text{pl}} T^3 
\,,
\end{align}
%
so we have decoupling (\(\Gamma / H < 1\)) when \(T < m _{\text{pl}}^{-1/3} G_x^{-2/3}\). 
This is a \emph{lower bound}! The situation is qualitatively different from the massless case. 

% Suppose that we are considering the gravitational interaction: in that case, we get \(T < m _{\text{pl}}\) since \(G_x\) is related to \( G_N\) 

% \todo[inline]{What is the relation?}
For the weak interaction, \(G_x\) is called the Fermi constant \(G_F \sim (\SI{300}{GeV})^{-2}\):\footnote{This value can be  experimentally measured from weak interactions, but it is consistent with the masses of the mediators being of the order of \SI{100}{GeV}.} this yields the bound
%
\begin{align}
T \lesssim \SI{1}{MeV}
\,,
\end{align}
%
which is why below \(\SI{1}{MeV}\) neutrinos are decoupled.

\todo[inline]{Then Pacciani \cite[]{paccianiAppuntiCorsoPhysical2018} applies the formula to gravitation setting \(G_x = G\) to find that it decouples at \(T \sim m_P\), but the graviton is massless!}

To summarize, interactions which are mediated by massless particles couple at a certain (high) temperature and are thereafter coupled.
On the other hand, interactions which are mediated by massive particles couple at a certain (high) temperature, stay coupled for a while, and then decouple again at a relatively low temperature. 

\section{Hydrogen recombination}

% Let us now consider the consequences of these decoupling conditions.
% First of all we look at the recombination of hydrogen.
In the early universe, at \(z \sim\) a few \(\times 1000\), there were free electrons and free protons.
The temperature had dropped below the binding energy of hydrogen, \SI{13.6}{eV}, quite a long time earlier, around \(z \sim \num{5e4}\), however as we will see in more detail the conditions were such that most hydrogen was still ionized. 

Around \(z \sim 2000\) the process of recombination\footnote{The process \(e^{-} + p \to H + \gamma \) is known as ``recombination'' for historical reasons, although electrons and protons were not re-combining, since bound hydrogen could not have existed earlier in the history of the universe.} started.
Then, around \(z \sim 1400 \divisionsymbol 1600\) \cite[table 9.1]{colespCosmology2002} the process started really picking up, crossing the half-way point for the fraction of hydrogen which was ionized. 

At around \(z \sim 1100\) the fraction of ionized hydrogen became so low that the universe became transparent to radiation. Photons which were being constantly scattered reached their last scattering and then kept going; the temperature at that point was \(T \sim \SI{3000}{K}\), so now we see the CMB as a thermal distribution at a temperature of \(\SI{3000}{K} / (1 + z) \approx \SI{2.7}{K}\).

Now, let us get to the details of how this all happened. 
% Protons first appeared in the universe as non-relativistic, at \(T \sim \SI{1}{MeV}\) while \(m_p \sim \SI{1}{GeV}\).

% At a certain point, it becomes possible to create neutral H atoms from these free particles.
% We will use a special case of the Boltzmann formula, which governs this and many other phenomena: the Saha equation.

% The reaction is \(e + p \leftrightarrow H + \gamma \). 
% We want to look at a density in phase space.
In order to precisely treat the process \(e^{-} + p \leftrightarrow H + \gamma \) we would need all the scattering matrix elements, as well as all the phase space densities of the particles.
This would allow us to treat a general distribution in phase space, even out of equilibrium.

What we will do instead is to provide a bulk estimate, making use of the Saha equation, which assumes we are at both thermal and chemical equilibrium.
It relates the chemical potentials of the particles as \(\mu _e + \mu_p = \mu_H + \mu_\gamma \); however we know that \(\mu_{\gamma }=0\), so we have 
%
\begin{align}
\mu _e + \mu _p = \mu _H
\,.
\end{align}

% The chemical potential \(\mu \) entered in the exponent of the FD and BE expressions.
Both electrons, protons and hydrogen atoms were nonrelativistic at this stage: therefore their number densities can be approximated with Boltzmann statistics (the low-energy approximation: equation \eqref{eq:boltzmann-statistics-number-density}),
%
\begin{align}
  n_e &= g_e \qty(\frac{m_e T}{2 \pi })^{3/2} \exp(\frac{\mu _e - m_e }{T})  \\
  n_p &= g_p \qty(\frac{m_p T}{2 \pi })^{3/2} \exp(\frac{\mu _p - m_p }{T})  \\
  n_H &= g_H \qty(\frac{m_H T}{2 \pi })^{3/2} \exp(\frac{\mu _H - m_H }{T}) 
  \,.
\end{align}

% Degeneracy is not an issue, since we are talking about cosmology.
The statistical weights here are \(g_e = g_p = 2\) and \(g_H = 4\) \cite[pag.\ 194]{colespCosmology2002}.\footnote{These numbers are given as fact here, they come from a quantum-mechanical study of the system.}
Also, we will later need the fact that the universe being globally neutral implies \(n_e = n_p\). 


% We get approximately
% %
% \begin{align}
%   n_H = \frac{g_H}{g_e g_p} n_e n_p \qty(\frac{m_e T}{2 \pi })^{-3/2}\exp(B/T)
% \,,
% \end{align}
% %
% but the universe is locally and globally neutral: \(n_e = n_p\), and \(n_b = n_p + n_H\). 

% We will see that most of the hydrogen we produce will not be when the temperature is of the order of the binding energy, but much later.

\end{document}
