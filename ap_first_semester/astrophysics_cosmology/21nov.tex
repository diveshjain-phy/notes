\documentclass[main.tex]{subfiles}
\begin{document}

% \marginpar{Thursday\\ 2019-11-21, \\ compiled \\ \today}
% \section*{Thu Nov 21 2019}

% We exponentiate the equation from before: 
% we get 
We can approximate this as 
%
\begin{align}
  X_d \approx X_n (1 - X_n)
  \exp(-29.33 + \frac{25.82}{T_9  } - \frac{3}{2} \log T_9 + \log ( \Omega_{0b} h^2 ))
\,,
\end{align}
%
where \(T_9  =  T / \SI{e9}{K}\). 
The factor \(\Omega_{0b} h^2\) comes from the scaling of the baryon-to-photon ratio \(\eta\) (equation \eqref{eq:baryon-to-photon-ratio}).

\todo[inline]{\textcite[]{paccianiAppuntiCorsoPhysical2018} says we use the exponential decay of the neutron population to find this formula: how does it come in, though?}

% \todo[inline]{What is going on? What is \(T_{\rho }\)? }

% We want to understand why there is so much He-4 in the universe, since it is destroyed in stars! 
Almost all the deuterium which is formed then turns into \ce{^{4}He}, so since those nuclei are as heavy as four neutrons, and two neutrons are needed to make each we can estimate that the helium mass fraction will be given by \(Y \approx 2 X_n \approx \num{.25}\). 
The calculation is quite rough, in order to do it properly we should use the Boltzmann equation. 

\todo[inline]{Very rough calculation\dots the corrective factor of \num{.8} is kind of thrown in there, also I think using \(\exp(-1.5)\) instead of \(\exp(-1.3)\) helps nudging the number and hides just how rough this is}

% \todo[inline]{This is indirect evidence for dark energy: why?}

This provides an experimental bound for many parameters: the lifetime of the neutron, for example, cannot be much shorter since otherwise too many would have decayed before forming deuterium. 

The reaction rate \(\Gamma \) for weak interactions, as we have discussed earlier, is given by \(\Gamma \sim G_F^2 T^5 \approx T^{5} / \tau _n\), where the Fermi coupling constant \(G_F\) is connected to the lifetime of the neutron \(\tau_n\) since that is also a weak-interaction process.

Then, the moment of decoupling \(\Gamma \sim H\) also constrains \(\tau _n\), since it happens at a temperature \(T_{d \nu } \sim G_F^{-2/3} m_P^{-1/3} \approx \tau_n^{4/3} m_P^{-1/3}\).\footnote{One might think that the lifetime of the neutron would be a well-established result in Earthly particle physics, but in fact there is a conflict between two different kinds of measurements \cite[]{wolchoverNeutronLifetimePuzzle}, so while the value is roughly known the error bars of these measurements do not overlap: this is the ``neutron lifetime puzzle''.}
% Let us suppose we increase the lifetime of neutrons, \(\tau_{1/2}\). 
% This changes the moment at which we reach equation \(\Gamma \sim H\). 

Increasing the lifetime of neutrons decreases the amount of He-4 in the universe. 

We know that the Hubble parameter is given by
%
\begin{align}
  H^2 = \frac{8 \pi G}{3} \underbrace{\frac{\pi^2}{30} g_{*}(T) T^4}_{\rho = \rho _r}
\,,
\end{align}
%
so \(H(T) \sim \sqrt{g_* (T)}\): this means that if we add more particles to our model which are coupled in the \(\sim \SI{}{MeV}\) range, thus increasing \(g_*\) at that temperature, we also increase \(H\), which means that the moment at which \(\Gamma < H\) comes about earlier, meaning that we get more Helium. 
This is very useful constraint on our models; for instance, any dark matter particle we hypothesize needs to not ``break baryogenesis''.

% If we fix the temperature, and change \(g_{*}\) (by adding degrees of freedom), then we get more He-4. 

% This gives us observational constraints on the additions of exotic particles to our theory, since that would change \(g_{*}\). 
% This bounds the number of neutrino families by \num{3.} something, so there cannot be more than \num{3} families of light neutrinos. 

% If gravitons are thermal, then they also contribute to radiation. 

Decreasing the baryon fraction \(\Omega_b\) inhibits the production of deuterium, since then there are more photons to disassociate them. 
We find that the model fits observation as long as \(\num{.011} h^{-2}\leq \Omega_{0b} \leq \num{.25} h^{-2}\); most people agree that we are near the upper bound of this range.

There is also another parameter, \(m_P \sim G^{-1/2}\): modified gravity theories often predict variations of the gravitational constant with time, but since this appears in our calculations we can constrain its value at that stage in the early universe.

\section{Dark Matter dynamics}

We have described how dark matter came to be accepted as a necessary component of the matter content of the universe, now we wish to understand what are its basic properties. 

Observationally, dark matter has no relevant electromagnetic interactions: in the low-redshift universe it only interacts gravitationally (it is \emph{decoupled}), and is able to cluster.

This allows us to distinguish it from dark energy, which instead is uniformly distributed. 

Models of dark matter can be classified into \textbf{Hot and Cold dark matter}: HDM and CDM. 
We can also have \emph{Warm} dark matter, which has intermediate properties.

In \textbf{HDM}, particles decoupled while they were ultrarelativistic, so they have very high thermal motion.
They move fast, and tend to destroy gravitational potential wells in which they might settle by moving out of them, and thus decreasing the quantity of matter there. 
Neutrinos were thought to be Dark Matter, and would have been classified as HDM. 

They do this on scales comparable to the maximum distance travelled by them: this is calculated as \(vt\), where \(v\) is their average thermal velocity, and \(t\) is the age of the universe. 

This means that the structures formed in the presence of HDM are larger than \(\num{e15} M_{\odot}\); however this seems to conflict with observation, since we also see smaller structures!
The hypothesis is then that they were formed later, by fragmentation: this is known as the \emph{top-down approach}. 

The top-down approach, however, is falsified by the observation of high-redshift quasars combined with the scale of the anisotropies of the CMB: in order to account fo high-redshift small-scale structures (we have seen stars at \(z \sim 20\)!) we would have to increase the amplitude of the anisotropies to a scale which is not compatible to the anisotropies we see in the CMB. 
This does not mean that HDM cannot exist, but it cannot make up most of the observed DM density. 

\textbf{CDM}, on the other hand, is dark matter which decoupled at a time when it was already nonrelativistic. 
A \emph{bottom-up} approach to structure formation is compatible with the existence of CDM.
This is the kind of dark matter which appears in the currently-accepted \(\Lambda\)CDM model of cosmology.

Although it is the best model to date, there are also issues with CDM, which are current research topics.
Dark matter is distributed in \emph{halos}, gravitationally-bound regions which contain dark matter and are currently decoupled from cosmic expansion.

One issue is that simulations predict small-scale halos in the larger ones, which are however not observed.
Also, the density profiles from simulations do not seem to match what is observed: they have a cusp in the center of the halo, while observations suggest that density profiles are flat in the center.

There are many proposed solutions to these problems: for example, dark matter could self-interact in ways other than gravitational, or it could be warm.

% We also have a bottom-up approach, which is compatible with CDM. 

% Now, neutrinos are not useful for cosmology. 

% We have \(\Gamma \sim T^{5}\), and \(\Gamma = H\): 
% \(T^{5} / \tau_{1/2} \sim T^2\) implies that \(\tau_{1/2} \sim T^{3}\). 

% The decouplig temperature for HDM is larger than the temperature at which they become nonrelativistic, which is of the order of the mass. 

% For CDM, instead, the decoupling temperature is \emph{smaller} than the temperature at which they become relativistic. 

\subsection{The Boltzmann equation and decoupling}

In order to understand how Dark Matter evolves, let us introduce the main equation used to analyze non-equilibrium phenomena: the \textbf{Boltzmann equation}. It describes the evolution of the phase space distribution of particles, \(f\). Its compact form is:
%
\begin{align}
  \mathbb{L} [f] = \mathbb{C} [f]
\,,
\end{align}
%
where \(\mathbb{L}\) is the \emph{Liouville operator}, which is a total derivative of the phase space density with respect to changes in time, position as well as momentum; while \(\mathbb{C}\) is the \emph{collision operator}, which describes the effect (in terms of variation per unit time) on the phase space distribution of collisions between particles --- it is written in terms of scattering matrices. 
% where all the scattering operators live on the RHS. 
In general, we should consider the phase space distribution of all the particle species, writing an equation for each of theses \(f_i\); now we will treat a single particle species for simplicity. 

This basic form is quite general: it can be used both for a simple Newtonian calculation and to include general-relativistic and quantum-mechanical effects.

We start with the Newtonian description: the phase space has position, momentum and time as coordinates, and a density function \(f(\vec{q}, \vec{p}, t)\) is defined on it. 

% The Einstein equations are blind to the momentum distribution, since \(T_{\mu \nu }\) does not depend on the momentum.
% We can say that all of the momentum has been marginalized. 

The classical form of the Liouville operator is the \emph{convective derivative},
%
\begin{subequations}
\begin{align}
  \mathbb{L} = \frac{D}{Dt} &= \pdv{}{t} + \dv{\vec{x}}{t} \cdot \nabla_x + \dv{\vec{p}}{t} \cdot \nabla_p   \\
  &= \pdv{}{t} + \vec{v} \cdot \nabla_x + \frac{\vec{F}}{m} \cdot \nabla_p 
\,. 
\end{align}
\end{subequations}

% Applying this to a classical fluid yields the Navier-Stokes equations, as long as we distinguish the force term \(\vec{F}\) into forces proportional to volume and forces proportional to area. 
This equation describes motion in much more detail than, say, the Navier-Stokes equations, since it allows for arbitrary momentum \emph{at each point} in space. 
We can recover the N-S equations, as well as the energy and mass conservation equations, by taking \emph{moments} of the Boltzmann equation: we multiply it by \(m \vec{v}\), or \(m v^2 / 2\), or \(m\), and integrate in \(\dd[3]{p}\).

In the Newtonian case, the force term \(\vec{F}\) includes gravity, which in GR instead is ``geometrized'', meaning that it is included in the inertial motion of the particles. 
The relativistic version of the Liouville operator is written in terms of position \(x^{\alpha }\) and momentum \(p^{\alpha } = \dv*{x^{\alpha }}{\lambda }\)
%
\begin{align}
\mathbb{L} 
&= \dv{x^{\alpha }}{\lambda } \pdv{}{x^{\alpha }} 
+ \dv{p^{\alpha }}{\lambda } \pdv{}{p^{\alpha }} \\ 
&= p^{\alpha } \partial_{\alpha } - \Gamma^{\alpha }_{\beta \gamma } p^{\beta } p^{\gamma } \pdv{}{p^{\alpha }}
\,.
\end{align}

\todo[inline]{Is the momentum supposed to be dimensionless or not? Setting \(\dv*{x^{\alpha }}{\lambda } = p^{\alpha }\) as well as \(p^2= m^2\) seems contradictory\dots}

This is because, since any particle must move along geodesics, \(p^{\alpha }\) must satisfy the geodesic equation: 
%
\begin{align}
\frac{Dp^{\alpha }}{Dt } =
\dv{p^{\alpha }}{\lambda } + \Gamma^{\alpha }_{\beta \gamma } p^{\beta } p^{\gamma }=0
\,.
\end{align}

% We can then write down the Christoffel bit of the geodesic equation instead of the derivative \(\dv*{p^{\alpha }}{\lambda }\).
We require that the particles are \emph{on shell}:
%
\begin{align}
  g^{\alpha \beta } p_{\alpha } p_{\beta } = m^2
\,,
\end{align}
%
meaning that we are neglecting the uncertainty principle and our discussion is relativistic but classical (not fully quantum-mechanical).

% We want to describe the \emph{abundance} of dark matter, in phase space: the number of DM particle per EM-interacting particle. 

Let us make this explicit, using the Christoffel symbols of the FLRW metric and assuming isotropy and homogeneity (which together imply that the phase space density \(f\) only depends on \(t\) and \(p^{0} = E\)): many terms vanish, and we are left with
% Acting on \(f\), we get 
%
\begin{align}
\mathbb{L}[f]  
= p^{0} \partial_{t}f - \Gamma^{0}_{ij} p^{i} p^{j} \pdv{f}{E}
= E \partial_t f - \frac{\dot{a}}{a} \abs{\vec{p}}^2 \pdv{f}{E}
\,,
\end{align}
%
% which we will not prove. 
% The derivative with respect to the momentum must be \(\partial_{p^{0}}\),
% \todo[inline]{because of isotropy?}
since the relevant Christoffel symbols (in Cartesian coordinates) are 
%
\begin{align}
  \Gamma^{0}_{ij } = \frac{\dot{a}}{a} \delta_{ij }
\,.
\end{align}

So, we can write the Boltzmann equation as 
%
\begin{align}
\pdv{f}{t} - \frac{\dot{a}}{a} \frac{p^2}{E} \pdv{f}{E} = \frac{\mathbb{C} [f]}{E}
\,.
\end{align}

% so in the end the equation becomes: 
% %
% \begin{align}
%   \hat{\mathbb{L}} = \dot{n} + 3 \frac{\dot{a}}{a} n 
% \,. 
% \end{align}
% %

% % Conventionally we divide by \(p^{0}\): we get for the Boltzmann equation: 
% %
% \begin{align}
%   \pdv{f}{t} - \frac{\dot{a}}{a } \frac{p^2}{E} \pdv{f}{E} = \frac{1}{E} \hat{\mathbb{C}} [f]
% \,.
% \end{align}

Let us now do what is also done in the classical case and integrate in \(\dd[3]{\vec{p}}\): we will lose detail in the description but gain in computability.
First, recall the definition of the number density from the phase space distribution:
%
\begin{align}
  n(t) = \frac{g}{(2\pi )^3} \int  \dd[3]{\vec{p}} f(\abs{\vec{p}}, t) 
\,,
\end{align}
%
which appears in the first term if we integrate the Boltzmann equation (also multiplying by \(g / (2 \pi )^3\)):
%
\begin{align}
  \pdv{n}{t} - \frac{g}{(2 \pi )^3} \frac{\dot{a}}{a } \int  \dd[3]{\vec{p}} \frac{p^2}{E} \dv{f}{E} = \frac{g }{(2\pi )^3} \int  \dd[3]{p} \frac{1}{E} \mathbb{C} [f]  
\,.
\end{align}
%
% More properly, we are doing \(\mathbb{L} \expval{f}\). 

The number density actually also appears in the second term: we can manipulate it as
%
\begin{subequations}
\begin{align}
  \int \dd[3]{p} \frac{p^2}{E} \pdv{f}{E} 
  &= 2 \int \dd[3]{p} p^2 \pdv{f}{(E^2)} 
  = 2 \int \dd[3]{p} p^2 \pdv{f}{(p^2)}  \marginnote{\(\dd{(E^2)} = 2 E \dd{E}\) and similarly for \(\dd{(p^2)}\).}\\
  &= \int \dd[3]{p} p \pdv[]{f}{p} 
  = 4 \pi \int_{0}^{ \infty } \dd{p} p^3 \pdv{f}{p}  \\
  &= \eval{4 \pi p^3 f}_{0}^{\infty } - 4 \pi \int_{0}^{\infty } \dd{p} 3 p^2 f 
  = -3 \int \dd[3]{p} f = -3n \frac{(2 \pi )^3}{g}
\,.
\end{align}
\end{subequations}

The boundary term vanishes since at \(0\) we have \(p=0\), and at (momentum) infinity we have \(f=0\) (since otherwise the energy would diverge). We are also moving back and forth between integrals in \(\dd[3]{p}\) and in \(\dd{p}\) times \(4 \pi \), which we can do because of isotropy.

So, we can see that the left-hand side is equal to \(\dot{n} + 3 \dot{a}n/a \), and we have the \textbf{cosmological Boltzmann equation}
%
\begin{align}
  \dot{n} + 3 \frac{\dot{a}}{a} n = \frac{g}{(2 \pi )^3} \int \dd[3]{p} \frac{1}{E} \hat{\mathbb{C}} [f]
\,.
\end{align}

% This is the cosmological version of the Boltzmann equation. 

Right away we can see that this makes sense in the decoupling limit: if there are no collisions the right-hand side must vanish, so we are left with 
%
\begin{align}
\dot{n} + 3 \frac{\dot{a}}{a} n = \dv{}{t} \qty(n a^3) = 0
\,,
\end{align}
%
meaning that \(n \propto a^{-3}\): this is the usual scaling of the number density, so our approach is working. 

Now we need to understand what the right-hand side looks if particle species are coupled. This is difficult in general, we will give an expression using ``bulk'' parameters:
%
\begin{align}
  \frac{g}{(2 \pi )^3} \int \frac{ \dd[3]{p}}{E} \hat{\mathbb{C}}[f] 
  = \Psi - \Gamma_A n
  = \Psi - \expval{\sigma v } n^2
\,,
\end{align}
%
where \(\Psi \) is the rate of creation of particles per unit volume, while \(\Gamma_A\) is the rate of annihilation. Note that \(\Psi \) has the dimensions \SI{}{s^{-1} m^{-3}}, while \(\Gamma _A\) has the dimensions \SI{}{s^{-1}}, so it needs to be multiplied by \(n\) in order to be dimensionally consistent. 
Physically speaking, the reason the term has that form is that the rate of annihilation must be proportional to the number density of particles there are at the moment.

The annihilation rate is found in terms of the cross section of the process, which we must average over all the momentum distribution of the particles: this is the reason for the appearance of \(\expval{\sigma v}\).

% where we have \(\Gamma_A = \expval{\sigma v} n\) times \(n\), where \(\Gamma \) is the rate of annihilation. 

At equilibrium, the left-hand side is equal to zero. The number density will be given by some equilibrium value, \(n _{\text{eq}}\): inserting this in the right-hand side, which must also vanish, we find \(\Psi = \expval{\sigma v} n^2 _{\text{eq}}\).
This result can then be used in general: the right-hand side is written as \(\expval{\sigma v} \qty(n^2 _{\text{eq}} - n^2)\).

\end{document}