\documentclass[main.tex]{subfiles}
\begin{document}

\section*{Thu Oct 17 2019}

\section{The mathematical description of curved spacetime}

The metric describes the spacetime. It depends on the coordinates.

\paragraph{Euclidean metric}

In 2D, it is \(\dd{s^2}  = \dd{x^2} + \dd{y^2} \). We can express it as 
%
\begin{equation}
  \dd{s^2} = \dd{x^{\mu }} \dd{x_{\mu }} = \dd{x^{\mu}} \dd{x^{\mu }} g_{\mu \nu } 
\,,
\end{equation}
%
computed with \(g_{\mu \nu } = \delta_{\mu \nu }\).

\paragraph{Polar coordinates}

Let us see how this changes when we change coordinates: for example, we can go to polar coordinates: 
%
\begin{equation}
    \begin{cases}
        x = r \cos(\theta ) \\
        y = r \sin(\theta ) 
    \end{cases}
    \qquad \qquad
    \begin{cases}
        r = \sqrt{x^2+y^2} \\
        \theta = \arctan(y/x)
    \end{cases}
\,.
\end{equation}
%

Let us compute the differentials \(\dd{x} \)   and \(\dd{y}\): 
%
\begin{equation}
  \dd{x} = \dd{r} \cos(\theta ) - r \sin(\theta ) \dd{\theta } 
\,,
\end{equation}
%
and 
%
\begin{equation}
  \dd{y} = \dd{r} \sin(\theta ) + r \cos(\theta ) \dd{\theta } 
\,.
\end{equation}
%

Plugging these into the metric and simplifying we get 
%
\begin{equation}
  \dd{s^2}  = \dd{r^2} + r^2 \dd{\theta^2} 
\,.
\end{equation}
%

It is not clear to see that these are equivalent.
We then want to compute scalar quantities to characterize them.

Another issue is the fact that the polar metric is singular at the origin: the metric should always have the same signature, and if it is nondegenerate (no zero eigenvalues) we should always be able to invert it: in this case however we'd also have to invert 
%
\begin{equation}
  g_{\mu \nu } = \left[\begin{array}{cc}
  1 & 0 \\ 
  0 & r^2
  \end{array}\right]
\,
\end{equation}
%
at \(r=0\): we cannot do it! This is a \emph{coordinate singularity}. There is nothing wrong with the space; \(\mathbb{R}^{2} \) is perfectly regular at \((0,0)\), but our coordinate description fails; besides, what value of \(\theta \) should we assign to that point? 

An \emph{arbitrarily large} change in \(\theta \) can result in an arbitrarily small distance travelled if we move close enough. 

\paragraph{Spherical coordinates}
In \(\mathbb{R}^3 \) we have the same issue. We use: 
%
\begin{equation}
  \begin{cases}
      x = \cos(\theta ) \cos(\varphi ) \\
      y = \cos(\theta ) \sin(\varphi)  \\
      z = \sin(\theta ) 
  \end{cases}
\,,
\end{equation}
%
and it is a simple computation as before to see that 
%
\begin{equation}
  g_{\mu \nu }= \left[\begin{array}{ccc}
  1 & 0 & 0 \\ 
  0 & r^2 & 0 \\ 
  0 & 0 & r^2 \sin(\theta )^2
  \end{array}\right]
\,,
\end{equation}
%
therefore these coordinates are not defined on the \emph{whole \(z\) axis}!

\paragraph{General coordinate transformations}

Now we consider a general transformation of space, which we denote by \(x^{\prime \mu } (x^{\mu })\): we see how the metric should change in order for the spacetime distance to be invariant: we define \(g_{\mu \nu }'\) by 
%
\begin{equation}
    g_{\mu \nu } \dd{x^{\mu }} \dd{x^{\nu }}
    \overset{!}{=}  
    g_{\mu \nu }' \dd{x^{\prime \mu }} \dd{x^{\prime \nu }}
\,.
\end{equation}
%

This means that the metric changes as a tensor: 
%
\begin{equation}
  g_{\mu \nu } \rightarrow
  g_{\mu \nu }' = 
  \pdv{x^{ \alpha }}{x^{\prime \mu }} 
  \pdv{x^{ \beta  }}{x^{\prime \nu  }} 
  g_{\alpha \beta }
\,,
\end{equation}
%
and we can see that it transforms as a \((0,2)\) tensor since the primes are in the denominator: it transforms with the \emph{inverse} of the Jacobian matrix.

The inverse metric transforms as: 
%
\begin{equation}
  g^{\mu \nu } \rightarrow
  g^{\prime \mu \nu } =
  \pdv{x^{\prime \mu  }}{x^{\alpha  }} 
  \pdv{x^{\prime \nu   }}{x^{\beta }}
  g^{\alpha \beta } 
\,,
\end{equation}
%
which we can check by proving that \(g^{\mu \nu }g_{\nu \rho  } = \delta^{\mu }_{\rho }\) is conserved when we transform both the metric and the inverse metric. We get: 
%
\begin{equation}
    g^{\prime \mu \nu } g_{\sigma \tau  }' \delta_{\nu }^{\sigma } =
    \pdv{x^{\prime \mu  }}{x^{\alpha  }} 
    \pdv{x^{\prime \nu   }}{x^{\beta }}
    g^{\alpha \beta } 
    \delta_{\nu }^{\sigma }
    \pdv{x^{ \pi  }}{x^{\prime \sigma  }} 
    \pdv{x^{ \lambda   }}{x^{\prime \tau  }} 
    g_{\pi  \lambda  }
\,,
\end{equation}
%
which can be simplified using the relations between the partial derivatives: 
%
\begin{equation}
    \pdv{x^{\prime \nu   }}{x^{\beta }}
    \delta_{\nu }^{\sigma }
    \pdv{x^{ \pi  }}{x^{\prime \sigma  }} 
    = \pdv{x^{\pi }}{x^{\beta }}
    = \delta^{\pi }_{\beta }
\,,
\end{equation}
%
since we are multiplying the Jacobian with its inverse, thus we get the identity. One can make this reasoning more explicit by seeing it as an application of the chain rule: \(x^{\mu }\) is a function of \(x^{\prime \mu }\) which is a function of \(x^{\mu } \).
Plugging this in we get 
%
\begin{equation}
    g^{\prime \mu \nu } g_{\sigma \tau  }' \delta_{\nu }^{\sigma } =
    \pdv{x^{\prime \mu  }}{x^{\alpha  }} 
    g^{\alpha \beta } 
    \delta^{\pi }_{\beta }
    \pdv{x^{ \lambda   }}{x^{\prime \tau  }} 
    g_{\pi  \lambda  }
\,,
\end{equation}
%
and now we can apply our hypothesis that \(g^{\alpha \beta }g_{\beta \lambda } = \delta^{\alpha }_{\lambda }\) to contract some more indices, get one more multiplication of a Jacobian with its inverse, which we can simplify in the same way as before to finally get the identity.
This proves that the inverse metric is a \((2,0)\) tensor.

\subsection{Lengths, areas, volumes and so on}

In 4D space, if we fix \(x^{0}\) and \(x^{3}\), we can consider an area element like \(\dd{A} = \sqrt{g_{11}} \dd{x^{}} \sqrt{g_{22}} \dd{x^{2}} \).

Similarly, the 4-volume is just 
%
\begin{equation}
  \dd{v} 
  = \sqrt{-g_{00}g_{11}g_{22}g_{33}}
  \dd{x^{0}} \dd{x^{1}} \dd{x^{2}} \dd{x^{3}} 
  = \sqrt{-g}
  \dd[4]{x} 
\,,
\end{equation}
%
where \(g = \det g_{\mu \nu }\). We have shown it for a diagonal metric, but it can be shown that it holds for any general metric. The minus sign comes from the fact that our metric has signature \(-1\) (and, as we will see, this holds in general): the determinant is then negative, and to take the square root we need a positive number.

\begin{claim}[Unproven]
    A metric can be always diagonalized, at least locally.
\end{claim}

When it is diagonal, then \(\dd{v} = \sqrt{-g} \dd[4]{x} \). Then the quantity \(\sqrt{-g} \dd[4]{x} \) is a scalar.

Intuitively, the claim follows from the equivalence principle: we put a free-falling observer in our space. They will perceive spacetime as being flat.

Under a diffeomorphism with the determinant of the jacobian equal to \(J\) we have the following transformation law for the determinant: 
%
\begin{equation}
  g' = J^{-2} g
  \qquad \implies \qquad
  \sqrt{-g'}  = J^{-1} \sqrt{-g} 
\,.
\end{equation}
%

This can be expressed by saying that \(\sqrt{-g} \) is a \emph{tensor density} of weight \(-1\).

\begin{definition}
A tensor density of weight \(w\) transforms just like a tensor, except we need to multply by a factor \(J^{w}\) in the transformation, where \(J\) is the determinant of the Jacobian of the transformation.

A \((p, q)\) \emph{tensor density} of weight \(w\) is an object \(M_{\mu_1 \dots \mu_p}^{\nu_1 \dots \nu_q}\) with many components indexed by \(p+q\) indices, which transforms as:

\begin{equation}
    M_{\mu_1 \dots \mu_p}^{\nu_1 \dots \nu_q}
    \rightarrow
    J^{w}
    \tensor{\Lambda}{_{\mu_1}^{\mu'_1}}\dots
    \tensor{\Lambda}{_{\mu_p}^{\mu'_p}}
    \tensor{\Lambda}{^{\nu_1}_{\nu'_1}}\dots
    \tensor{\Lambda}{^{\nu_q}_{\nu'_q}}
    M_{\mu_1' \dots \mu_p'}^{\nu_1' \dots \nu_q'}
\end{equation}
%
under diffeomorphisms with Jacobian matrix \(\tensor{\Lambda}{_\mu^\nu}\), with determinant \(J\).
\end{definition}

When we transform the 4-volume element \(\dd[4]{x'} = J \dd[4]{x} \), we get a Jacobian: the element \(\dd[4]{x} \) is a \emph{tensor density of weight 1}.

Then we see that the volume element \(\sqrt{-g} \dd[4]{x} \) is a \emph{scalar}, since when multiplying tensor densities their weights are added.

\subsection{Vectors in curved spacetime}

They are not objects \emph{in spacetime}: instead they belong to the \emph{tangent space}.

For each point \(x\) in the manifold we define a basis at that point: \(\qty{e^{\mu }_{(\alpha )}}(x)\), where \(\mu \) is a vector index while \((\alpha )\) denotes which vector we are considering.

Any vector \(a^{\mu }(x)\) can be then decomposed as  
%
\begin{equation}
  a^{\mu }(x) = a^{(\alpha) }(x) e^{\mu }_{(\alpha )}(x)
\,.
\end{equation}
%

Since spacetime is not flat, the dependence on \(x\) is not trivial.

The scalar product between the vectors can be expressed with respect to the basis: 
%
\begin{equation}
  a(x) \cdot b(x) = a^{(\alpha )} b^{(\beta )} e_{(\alpha )}\cdot e_{(\beta )}
\,,
\end{equation}
%
and we can select our basis so that at every point it is orthonormal: 
%
\begin{equation}
    e_{(\alpha )}\cdot e_{(\beta )} = \eta_{(\alpha ) (\beta )}
\,.
\end{equation}
%

We \emph{cannot sum vectors in different tangent spaces}.
But we want to: we need to define derivatives!
To solve this issue, we will introduce the notion of \emph{parallel transport}.

\end{document}