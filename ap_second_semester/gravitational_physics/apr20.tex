\documentclass[main.tex]{subfiles}
\begin{document}

\marginpar{Monday\\ 2020-4-20, \\ compiled \\ \today}

% The Fourier transform is stochastic since the noise is stochastic: however, the PSD encompasses the statistical properties of the signal in a way that is stationary and well-defined. 

A physical system is a \textbf{functional} \(F\) which transforms one or many input time series \(i_j (t)\) into one or many output time series \(o_j (t) = F(i_j(t))\). 

In principle, any output time series at any time could be a function of any input time series at any time.
However, real systems are causal: there cannot be causality going backward in time, so \(o(t_0 ) = \eval{F (i(t))}_{t \leq t_0 }\). 

% Also, often we can approximate systems as linear ones. as long as we work near a single point. 
% Also, we can sometimes approximate them as stationary. 
We can also make two assumptions: that the functional \(F\) is \textbf{linear} --- this is justified as long as we are always working near a fixed point, so that the higher order terms are negligible; and that the functional \(F\) is \textbf{stationary}: this means that it is invariant under translations \(t \to t + a\).

Under all of these assumptions, we can express the effect of the system through an \textbf{impulse response function} \(h\), defined so that: 
%
\begin{align}
o(t) = F \qty[\int \dd{\widetilde{t}} i (\widetilde{t}) \delta(t - \widetilde{t})]
= \int \dd{\widetilde{t}} i(\widetilde{t}) F( \delta (t - \widetilde{t})) 
= \int \dd{\widetilde{t}} i(\widetilde{t}) h(t - \widetilde{t})
\,.
\end{align}

We can say that \(F[i(\widetilde{t}) \delta] = i(\widetilde{t}) F[\delta ]\) because \(t'\) is fixed inside the integral, so \(i(\widetilde{t})\) is just a constant. 

We used stationarity to write \(h(\widetilde{t}, t)\) as \(h( \widetilde{t} - t)\); also, causality tell us that the IRF \(h(\tau )\) must satisfy \(h(\tau ) = 0\) for \(\tau < 0\).

The expression for the output as a function of the input is a convolution, so in Fourier space it is a product;
%
\begin{align}
o(\omega ) = i(\omega ) h(\omega )
\,.
\end{align}

The power spectral density then transforms as \(S_o (\omega ) = \abs{h(\omega )}^2 S_i (\omega )\), and if we have systems in series we can just multiply the impulse responses together, like 
%
\begin{align}
o (\omega ) = i(\omega )\prod_{j = 1}^{N} h_j (\omega ) 
\,.
\end{align}

\subsection{Sampling}

Often we sample signals digitally.
Analogic systems can be faster, but electronics are getting very fast as well, and they are easier to use.

The signal is quantized in two ways: we quantize both in time by sampling at an interval \(t_s\) and in amplitude, by encoding it with a finite number of bits.
This introduces noise, which is well-known and easy to calculate.
We still need to do Fourier analysis, but we will use a discrete Fourier transform.

\subsubsection{Aliasing}

If we have a signal at a frequency \(f\), and we want to reconstruct it, we need to sample at a frequency \(\geq 2f\).

If we sample at \SI{100}{Hz}, we can only accurately describe signals up to \SI{50}{Hz}. 
This is the \textbf{Nyquist-Shannon sampling theorem}.

This is true if we want to fit the data with the slowest sinusoid possible; if we know in which frequency range we should look we can try to fit higher-frequency sinusoids but this is risky business.
If we work below the Nyquist frequency we can be sure of each frequency we see.

\section{Resonant bar detectors}

\subsection{Two paths to GW detection}

Most modern and planned GW detectors operate by constructing \textbf{free-falling masses}: ground-based interferometers bounce signals off of suspended mirrors, space based ones have masses in actual geodesic motion. 
These detectors are \emph{broad-band}, which is useful, but each frequency has to be detected at its native amplitude with no amplification. 
They can be made on \emph{large scales}, on the order of \SI{e3}{m} on Earth, \SI{e9}{m} in space. This is very useful scientifically, since then the GW-induced displacement is larger; however it requires a lot of infrastructure and investment. 
These must then be built and operated by large collaborations, with hundreds of people at least. 

Another option, which was quite popular a few years ago, is to use an \textbf{elastic body} which resonates at a specific frequency. 
This might \emph{enhance} the effect of a GW through resonance and \emph{extend} the duration of burst signals. 

However, this kind of detector is only sensitive \emph{around its resonant frequency}. 
Also, since it extends the signal it is hard to precisely reconstruct the \emph{temporal profile} of the signal. 

These need to be isolated solid objects: they will fit in a lab (at scales of \SI{e1}{m} at most), but the GW-induced displacements will be small. 

% On the other side, we have \textbf{interferometers} which measure the distance between free-falling masses. 

\subsection{Harmonic oscillators and GW}

\subsubsection{Harmonic oscillators}

Suppose we have a perfect harmonic oscillator with a time-dependent rest position \(x_0(t) \) and a time-dependent external force \(F _{\text{ext}} (t)\): its evolution will be determined by the differential equation 
%
\begin{align}
m \ddot{x} = -k (x(t) - x_0 (t) ) + F _{\text{ext}} (t)
\,,
\end{align}
%
which in Fourier space can be written as 
%
\begin{align}
- m \omega^2 x(\omega ) &= - k (x(\omega ) - x_0 (\omega )) + F _{\text{ext}} (\omega )  \\
x(\omega ) &= \frac{k x_0 (\omega ) + F _{\text{ext}}(\omega )}{k - m \omega^2} = \frac{k x_0 (\omega ) + F _{\text{ext}}(\omega )}{k \qty(1 - \omega^2 / \omega_0^2)}  \\
&= \underbrace{\frac{\omega_0^2}{1 - \omega^2 /\omega_0^2}}_{H_{x_0 }(\omega )}
x_0 (\omega ) + 
\underbrace{\frac{F _{\text{ext}} (\omega )}{k (1 - \omega^2 / \omega_0^2)} }_{H_{F _{\text{ext}}} (\omega )}
F _{\text{ext}}(\omega )
\,,
\end{align}
%
where we defined \(\omega_0 = \sqrt{k / m}\) and the two transfer functions \(H_{x_0 }\) and \(H_{F _{\text{ext}}}\).

This diverges for \(\omega = \omega_0 \); but let us consider the effect of \textbf{velocity damping}: we add a term \(- \beta \dot{x}\) to the RHS of the differential equation,
%
\begin{align}
m \ddot{x} = - k \qty(x(t) - x_0 (t)) - \beta \dot{x}(t) + F _{\text{ext}}(t)
\,,
\end{align}
%
which in Fourier space becomes:
%
\begin{align}
x(\omega ) = \frac{k x_0 (\omega ) + F _{\text{ext}}(\omega )}{k \qty(1 - \qty( \frac{\omega}{\omega_0 })^2 - \frac{i \omega \beta }{k})}
\,,
\end{align}
%
since every derivative becomes \(- i \omega \). 

Another kind of damping we can have is called \textbf{structural internal damping}, which means modifying the differential equation as:
%
\begin{align}
m \ddot{x} = - k (1 + i \delta ) \qty(x(t) - x_0 (t)) + F _{\text{ext}}(t)
\,;
\end{align}
%
concretely speaking this means that there is some \emph{delay} between the action of the force and the response of the system. In Fourier space, this means 
%
\begin{align}
x(\omega ) = \frac{k x_0 (\omega ) + F _{\text{ext}}(\omega )}{k \qty(1 - \qty( \frac{\omega}{\omega_0 })^2 + i \delta )}
\,,
\end{align}
%
so, since both terms add a purely imaginary constant to the denominator, we encapsulate them into a term \(i / Q\), for an arbitrary \(Q\). 

This \(Q\) quantifies damping (inversely: large \(Q\) means small damping). For non-infinite values of \(Q\), the transfer function does not diverge.
% The transfer function is more peaked for less damping. 

\subsubsection{GW interactions}

How do we see the effect of GW on an elastic body?
Consider two masses, which start out free-falling, and connect them by a spring: they now will not move along geodesics.
If we move to the \textbf{proper detector frame}, the effect of a GW can be described as a Newtonian force on the test masses, which together with the reaction of the spring determines the motion of the system:
%
\begin{align}
F _{\text{GW}} - k (L - \Delta x) = m \Delta \ddot{x}
\,,
\end{align}
%
where the force is given by (equation \eqref{eq:geodesic-deviation-detector-frame} multiplied by \(m\)):
%
\begin{align}
F_{\text{GW}} = \frac{m}{2} \ddot{h}^{TT}_{xx} \Delta x \approx \frac{m}{2} L \ddot{h}^{TT}_{xx}
\,.
\end{align}

Since we can only see \(h_{xx}\), we are only sensitive to the \(h_{+}\) polarization: this is not surprising, since our detector is one-dimensional. 

Note that this expression is only valid as long as we are in the short arm approximation: \(L \ll \lambda _{\text{GW}}\), which means \(f _{\text{GW}} \ll c/ L \approx \SI{3e8}{Hz}\), if \(L \approx \SI{1}{m}\). 

Intuitively, what the equation is describing is the force of the GW competing with the intrinsic one of the oscillator to move the mass.

The oscillator was a convenient approximation to give an idea of the system, but really for our detector we will use a continuous \textbf{resonant bar}; we can describe its movement by introducing the variable \(u(x, t)\), which denotes the displacement from equilibrium at a certain point (still in only \emph{one dimension}). The dynamics of the bar can be shown to obey the law
%
\begin{align}
\dd{m} \qty(\pdv[2]{u}{t} - v_s^2 \pdv[2]{u}{x}) = \dd{F_x} = \dd{m} \frac{1}{2} x \ddot{h}_{xx}^{TT}
\,,
\end{align}
%
where \(v_s\) is the speed of sound in the medium. 
\todo[inline]{Lagrangian or Eulerian?}

We assume that the ends of the bar are kept stationary:
%
\begin{align}
\eval{\pdv{u}{x}}_{x = \pm L/2} = 0
\,.
\end{align}

The general solution will be given by a sum of sines and cosines, but the cosines will move the center of the bar. 

\todo[inline]{They will, but we imposed the ends being stationary, not the center (and why should the center be stationary)! Why should we not use that condition instead? It works just as well, since \emph{cosines} satisfy the condition of being zero at \(\pm L/2\), and we get cosines from the first derivative of sines.}

Keeping only the physical sines we will then have the harmonic decomposition
%
\begin{align}
u(t, x) = \sum _{n=0}^{ \infty } \xi_{n} \sin( \frac{\pi x}{L} (2 n + 1))
\,,
\end{align}
%
which we can plug into the differential equation: computing the derivatives explicitly we find 
%
\begin{align}
\sum _{n=0}^{ \infty } \bigg(\ddot{\xi}_{n} + \underbrace{\qty( \frac{v_s \pi (2n+1)}{L})^2}_{\mathclap{\omega_{n}^2}}\bigg) \sin( \frac{\pi x}{L} (2 n+1)) = \frac{1}{2} x \ddot{h}^{TT}_{xx}
\,,
\end{align}
%
which, in \(L^2\) space, is in the form \(\sum _{n} c_n \hat{e}_{n} = \vec{v}\), where \(\hat{e}_n\) are orthogonal basis vectors while \(\vec{v}\) is a vector (recall that \(\ddot{h}_{xx}^{TT}\) is approximately  constant with respect to \(x\), but it is multiplied by \(x\)).
In order to solve it, we take its scalar \(L^2\) product with an arbitrary basis vector, which amounts to multiplying by another sinusoid and integrating. 

The sinusoids \(\hat{e}_{n} = \sin((2n+1) \pi x / L)\) are not orthonormal, they instead satisfy \(\hat{e}_n \cdot \hat{e}_{m} = (L/2) \delta_{nm}\) as can be checked by direct computation. On the other side of the equation we find 
%
\begin{align}
\hat{e}_{m} \cdot \vec{v} &= \frac{1}{2} \ddot{h}^{TT}_{xx} \int_{-L/2}^{L/2}  \dd{x} x \sin( \frac{\pi x}{L} (2 m + 1))  \\
&= \frac{1}{2} \ddot{h}^{TT}_{xx} \frac{L^2}{\pi^2 (2m+1)^2} \underbrace{\eval{\sin( \frac{\pi x}{L} (2 m + 1))}_{-L/2}^{L/2}}_{= 2 (-)^{m}} \marginnote{The indefinite integral also has a term like \(x \cos(x)\), which is odd and vanishes.}  
\,,
\end{align}
%
so the final equation reads: 
%
\begin{align}
\ddot{\xi}_{n} + \omega^2_{n} \xi_{n} = \frac{(-)^{n}}{(2n+1)^2} \frac{2L}{\pi^2} \ddot{h}^{TT}_{xx}
\,.
\end{align}

We have eliminated (``integrated out'') the spatial part: we can analyze the time evolution by itself. 

\end{document}
