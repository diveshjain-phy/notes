\documentclass[main.tex]{subfiles}
\begin{document}

\subsection{Parameter estimation}

\marginpar{Monday\\ 2020-5-18, \\ compiled \\ \today}

Now, suppose we have found a candidate signal. How do we estimate the most likely set of parameters?

We do it by 
%
\begin{align}
\mathbb{P}(\vec{p} | \text{data}) = \mathbb{P} (\text{data} | \vec{p}) \mathbb{P} (\vec{p})
\,,
\end{align}
%
where we usually assume a flat prior for the parameters.

Thee output signal is in the form \(s(t) = h (t, \widetilde{p}) + n_0 (t)\), the GW plus the noise. So, we get  
%
\begin{align}
\mathbb{P}(n_0 ) = N \exp( - \frac{1}{2} \int_{- \infty }^{ \infty } \frac{\abs{n_0 (f)}^2}{S_n(f)^2} \dd{f}) = N \exp( -\frac{(n_0 \cdot n_0 )}{2})
\,,
\end{align}
%
by the scalar product we defined earlier.
This gives the probability of a specific realization of the noise. So, we get 
%
\begin{align}
n= s - h (\widetilde{p}) 
\,,
\end{align}
%
so we can evaluate \(\Lambda (s | \widetilde{p})\), which is defined as the likelihood of the data given the parameter vector \(\widetilde{p}\), as 
%
\begin{align}
\Lambda (s| \widetilde{p})
= N \exp( -\frac{(s - \widetilde{h}) \cdot (s - \widetilde{h})}{2})
= N \exp(- \frac{s \cdot s + h \cdot h + 2 s \cdot h}{2})
\,,
\end{align}
%
which we can calculate explicitly.
The term given by \(s \cdot s\) can be included in the normalization, since it is a constant with respect to the signal given. 

This allows us to compute the likelihood of the parameters. 
%
\begin{align}
\mathbb{P}(\widetilde{p} | \text{data}) = 
N \exp(- \frac{h \cdot h + 2 s \cdot h}{2}) \mathbb{P}(\widetilde{p})
\,,
\end{align}
%
where the scalar product is always the functional one which includes the PSD.

Then, we have different approaches:
\begin{enumerate}
    \item \textbf{maximum likelihood} means that we maximize \(\Lambda (s | \hat{p})\). This ignores the prior, and is equivalent to maximizing \(S / N\) for matched filtering. 
    \item \textbf{maximum posterior} means we maximize \(\mathbb{P}(\hat{p} | s)\). 
    \item \textbf{Bayes estimator}: we compute 
    %
    \begin{align}
    \hat{p}_{i}^{B} = \int \dd{\vec{p}} p_{i} \mathbb{P}(\vec{p} | s)
    \,.
    \end{align}
    
    This minimizes the error for each parameter.
\end{enumerate}

Some other data analysis methods: coherent wave bursts is for short-lived signals for which we do not have a model. 

We must give an estimate of the PSD which is ``mesoscopic'': we average on something like ten minutes, so that we average over any GW signal we could see, but do not average on too long a timescale so we have things which are normalized appropriately --- we must recalibrate often, because of wind, day-night and so on.

We can search for monochromatic signals: the stdev of their distribution in frequency around a specific one should go as the observation time to the \(-1/2\).

This must be done during long times.

As for the stochastic background: we could extract it from the PSD of the signal if we knew the detector PSD precisely.

Ideally, we would want to correlate signals from detectors at a distance \(D\) such that 
%
\begin{align}
\lambda_{GW} \geq D \geq L _{\text{noise}}
\,.
\end{align}

\section{LISA}

It's approved by ESA to launch in 2034. 
There's no seismic noise in space. 
It will be sensitive in the \num{.1} to \SI{100}{mHz} signals. 
Possibly, it will be able to see even further.
Now, the wavelengths will be in the length scale of the arm of the detector. 



\end{document}
